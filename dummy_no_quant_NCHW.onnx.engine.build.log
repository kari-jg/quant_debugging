&&&& RUNNING TensorRT.trtexec [TensorRT v8601] # trtexec --verbose --nvtxMode=verbose --buildOnly --workspace=8192 --onnx=one_layer_model_gen/onnx_dummies/dummy_no_quant_NCHW.onnx --saveEngine=one_layer_model_gen/engine_data_no_quant_NCHW_fp32_chw/dummy_no_quant_NCHW.onnx.engine --timingCacheFile=./timing.cache --fp16 --inputIOFormats=fp32:chw --outputIOFormats=fp32:chw --shapes=input_1:0:32x3x128x128
[08/21/2023-14:51:55] [W] --workspace flag has been deprecated by --memPoolSize flag.
[08/21/2023-14:51:55] [W] --buildOnly flag has been deprecated by --skipInference flag.
[08/21/2023-14:51:55] [W] --nvtxMode flag has been deprecated by --profilingVerbosity flag.
[08/21/2023-14:51:55] [W] --profilingVerbosity=verbose has been deprecated by --profilingVerbosity=detailed.
[08/21/2023-14:51:55] [I] === Model Options ===
[08/21/2023-14:51:55] [I] Format: ONNX
[08/21/2023-14:51:55] [I] Model: one_layer_model_gen/onnx_dummies/dummy_no_quant_NCHW.onnx
[08/21/2023-14:51:55] [I] Output:
[08/21/2023-14:51:55] [I] === Build Options ===
[08/21/2023-14:51:55] [I] Max batch: explicit batch
[08/21/2023-14:51:55] [I] Memory Pools: workspace: 8192 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[08/21/2023-14:51:55] [I] minTiming: 1
[08/21/2023-14:51:55] [I] avgTiming: 8
[08/21/2023-14:51:55] [I] Precision: FP32+FP16
[08/21/2023-14:51:55] [I] LayerPrecisions: 
[08/21/2023-14:51:55] [I] Layer Device Types: 
[08/21/2023-14:51:55] [I] Calibration: 
[08/21/2023-14:51:55] [I] Refit: Disabled
[08/21/2023-14:51:55] [I] Version Compatible: Disabled
[08/21/2023-14:51:55] [I] TensorRT runtime: full
[08/21/2023-14:51:55] [I] Lean DLL Path: 
[08/21/2023-14:51:55] [I] Tempfile Controls: { in_memory: allow, temporary: allow }
[08/21/2023-14:51:55] [I] Exclude Lean Runtime: Disabled
[08/21/2023-14:51:55] [I] Sparsity: Disabled
[08/21/2023-14:51:55] [I] Safe mode: Disabled
[08/21/2023-14:51:55] [I] Build DLA standalone loadable: Disabled
[08/21/2023-14:51:55] [I] Allow GPU fallback for DLA: Disabled
[08/21/2023-14:51:55] [I] DirectIO mode: Disabled
[08/21/2023-14:51:55] [I] Restricted mode: Disabled
[08/21/2023-14:51:55] [I] Skip inference: Enabled
[08/21/2023-14:51:55] [I] Save engine: one_layer_model_gen/engine_data_no_quant_NCHW_fp32_chw/dummy_no_quant_NCHW.onnx.engine
[08/21/2023-14:51:55] [I] Load engine: 
[08/21/2023-14:51:55] [I] Profiling verbosity: 2
[08/21/2023-14:51:55] [I] Tactic sources: Using default tactic sources
[08/21/2023-14:51:55] [I] timingCacheMode: global
[08/21/2023-14:51:55] [I] timingCacheFile: ./timing.cache
[08/21/2023-14:51:55] [I] Heuristic: Disabled
[08/21/2023-14:51:55] [I] Preview Features: Use default preview flags.
[08/21/2023-14:51:55] [I] MaxAuxStreams: -1
[08/21/2023-14:51:55] [I] BuilderOptimizationLevel: -1
[08/21/2023-14:51:55] [I] Input(s): fp32:chw
[08/21/2023-14:51:55] [I] Output(s): fp32:chw
[08/21/2023-14:51:55] [I] Input build shape: input_1:0=32x3x128x128+32x3x128x128+32x3x128x128
[08/21/2023-14:51:55] [I] Input calibration shapes: model
[08/21/2023-14:51:55] [I] === System Options ===
[08/21/2023-14:51:55] [I] Device: 0
[08/21/2023-14:51:55] [I] DLACore: 
[08/21/2023-14:51:55] [I] Plugins:
[08/21/2023-14:51:55] [I] setPluginsToSerialize:
[08/21/2023-14:51:55] [I] dynamicPlugins:
[08/21/2023-14:51:55] [I] ignoreParsedPluginLibs: 0
[08/21/2023-14:51:55] [I] 
[08/21/2023-14:51:55] [I] === Inference Options ===
[08/21/2023-14:51:55] [I] Batch: Explicit
[08/21/2023-14:51:55] [I] Input inference shape: input_1:0=32x3x128x128
[08/21/2023-14:51:55] [I] Iterations: 10
[08/21/2023-14:51:55] [I] Duration: 3s (+ 200ms warm up)
[08/21/2023-14:51:55] [I] Sleep time: 0ms
[08/21/2023-14:51:55] [I] Idle time: 0ms
[08/21/2023-14:51:55] [I] Inference Streams: 1
[08/21/2023-14:51:55] [I] ExposeDMA: Disabled
[08/21/2023-14:51:55] [I] Data transfers: Enabled
[08/21/2023-14:51:55] [I] Spin-wait: Disabled
[08/21/2023-14:51:55] [I] Multithreading: Disabled
[08/21/2023-14:51:55] [I] CUDA Graph: Disabled
[08/21/2023-14:51:55] [I] Separate profiling: Disabled
[08/21/2023-14:51:55] [I] Time Deserialize: Disabled
[08/21/2023-14:51:55] [I] Time Refit: Disabled
[08/21/2023-14:51:55] [I] NVTX verbosity: 2
[08/21/2023-14:51:55] [I] Persistent Cache Ratio: 0
[08/21/2023-14:51:55] [I] Inputs:
[08/21/2023-14:51:55] [I] === Reporting Options ===
[08/21/2023-14:51:55] [I] Verbose: Enabled
[08/21/2023-14:51:55] [I] Averages: 10 inferences
[08/21/2023-14:51:55] [I] Percentiles: 90,95,99
[08/21/2023-14:51:55] [I] Dump refittable layers:Disabled
[08/21/2023-14:51:55] [I] Dump output: Disabled
[08/21/2023-14:51:55] [I] Profile: Disabled
[08/21/2023-14:51:55] [I] Export timing to JSON file: 
[08/21/2023-14:51:55] [I] Export output to JSON file: 
[08/21/2023-14:51:55] [I] Export profile to JSON file: 
[08/21/2023-14:51:55] [I] 
[08/21/2023-14:51:55] [I] === Device Information ===
[08/21/2023-14:51:55] [I] Selected Device: NVIDIA RTX A2000
[08/21/2023-14:51:55] [I] Compute Capability: 8.6
[08/21/2023-14:51:55] [I] SMs: 26
[08/21/2023-14:51:55] [I] Device Global Memory: 5922 MiB
[08/21/2023-14:51:55] [I] Shared Memory per SM: 100 KiB
[08/21/2023-14:51:55] [I] Memory Bus Width: 192 bits (ECC disabled)
[08/21/2023-14:51:55] [I] Application Compute Clock Rate: 1.2 GHz
[08/21/2023-14:51:55] [I] Application Memory Clock Rate: 6.001 GHz
[08/21/2023-14:51:55] [I] 
[08/21/2023-14:51:55] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.
[08/21/2023-14:51:55] [I] 
[08/21/2023-14:51:55] [I] TensorRT version: 8.6.1
[08/21/2023-14:51:55] [I] Loading standard plugins
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::ModulatedDeformConv2d version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::Proposal version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::Split version 1
[08/21/2023-14:51:56] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[08/21/2023-14:51:56] [I] [TRT] [MemUsageChange] Init CUDA: CPU +520, GPU +0, now: CPU 537, GPU 1061 (MiB)
[08/21/2023-14:51:56] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.6.1
[08/21/2023-14:51:56] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.6.1
[08/21/2023-14:52:01] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1436, GPU +266, now: CPU 2050, GPU 1316 (MiB)
[08/21/2023-14:52:01] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[08/21/2023-14:52:01] [I] Start parsing network model.
[08/21/2023-14:52:01] [I] [TRT] ----------------------------------------------------------------
[08/21/2023-14:52:01] [I] [TRT] Input filename:   one_layer_model_gen/onnx_dummies/dummy_no_quant_NCHW.onnx
[08/21/2023-14:52:01] [I] [TRT] ONNX IR version:  0.0.7
[08/21/2023-14:52:01] [I] [TRT] Opset version:    13
[08/21/2023-14:52:01] [I] [TRT] Producer name:    tf2onnx
[08/21/2023-14:52:01] [I] [TRT] Producer version: 1.10.1 a37f29
[08/21/2023-14:52:01] [I] [TRT] Domain:           
[08/21/2023-14:52:01] [I] [TRT] Model version:    0
[08/21/2023-14:52:01] [I] [TRT] Doc string:       
[08/21/2023-14:52:01] [I] [TRT] ----------------------------------------------------------------
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 2
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::ModulatedDeformConv2d version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::Split version 1
[08/21/2023-14:52:01] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[08/21/2023-14:52:01] [V] [TRT] Adding network input: input_1:0 with dtype: float32, dimensions: (-1, 3, 128, 128)
[08/21/2023-14:52:01] [V] [TRT] Registering tensor: input_1:0 for ONNX tensor: input_1:0
[08/21/2023-14:52:01] [V] [TRT] Importing initializer: StatefulPartitionedCall/model/enc_conv_2/Conv2D/ReadVariableOp:0
[08/21/2023-14:52:01] [V] [TRT] Importing initializer: StatefulPartitionedCall/model/enc_conv_1/Conv2D/ReadVariableOp:0
[08/21/2023-14:52:01] [V] [TRT] Parsing node: StatefulPartitionedCall/model/enc_conv_1/Conv2D [Conv]
[08/21/2023-14:52:01] [V] [TRT] Searching for input: input_1:0
[08/21/2023-14:52:01] [V] [TRT] Searching for input: StatefulPartitionedCall/model/enc_conv_1/Conv2D/ReadVariableOp:0
[08/21/2023-14:52:01] [V] [TRT] StatefulPartitionedCall/model/enc_conv_1/Conv2D [Conv] inputs: [input_1:0 -> (-1, 3, 128, 128)[FLOAT]], [StatefulPartitionedCall/model/enc_conv_1/Conv2D/ReadVariableOp:0 -> (32, 3, 3, 3)[FLOAT]], 
[08/21/2023-14:52:01] [V] [TRT] Convolution input dimensions: (-1, 3, 128, 128)
[08/21/2023-14:52:01] [V] [TRT] Registering layer: StatefulPartitionedCall/model/enc_conv_1/Conv2D for ONNX node: StatefulPartitionedCall/model/enc_conv_1/Conv2D
[08/21/2023-14:52:01] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 32
[08/21/2023-14:52:01] [V] [TRT] Convolution output dimensions: (-1, 32, 128, 128)
[08/21/2023-14:52:01] [V] [TRT] Registering tensor: StatefulPartitionedCall/model/enc_conv_1/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model/enc_conv_1/Conv2D:0
[08/21/2023-14:52:01] [V] [TRT] StatefulPartitionedCall/model/enc_conv_1/Conv2D [Conv] outputs: [StatefulPartitionedCall/model/enc_conv_1/Conv2D:0 -> (-1, 32, 128, 128)[FLOAT]], 
[08/21/2023-14:52:01] [V] [TRT] Parsing node: StatefulPartitionedCall/model/re_lu/Relu [Relu]
[08/21/2023-14:52:01] [V] [TRT] Searching for input: StatefulPartitionedCall/model/enc_conv_1/Conv2D:0
[08/21/2023-14:52:01] [V] [TRT] StatefulPartitionedCall/model/re_lu/Relu [Relu] inputs: [StatefulPartitionedCall/model/enc_conv_1/Conv2D:0 -> (-1, 32, 128, 128)[FLOAT]], 
[08/21/2023-14:52:01] [V] [TRT] Registering layer: StatefulPartitionedCall/model/re_lu/Relu for ONNX node: StatefulPartitionedCall/model/re_lu/Relu
[08/21/2023-14:52:01] [V] [TRT] Registering tensor: StatefulPartitionedCall/model/re_lu/Relu:0 for ONNX tensor: StatefulPartitionedCall/model/re_lu/Relu:0
[08/21/2023-14:52:01] [V] [TRT] StatefulPartitionedCall/model/re_lu/Relu [Relu] outputs: [StatefulPartitionedCall/model/re_lu/Relu:0 -> (-1, 32, 128, 128)[FLOAT]], 
[08/21/2023-14:52:01] [V] [TRT] Parsing node: StatefulPartitionedCall/model/enc_conv_2/Conv2D [Conv]
[08/21/2023-14:52:01] [V] [TRT] Searching for input: StatefulPartitionedCall/model/re_lu/Relu:0
[08/21/2023-14:52:01] [V] [TRT] Searching for input: StatefulPartitionedCall/model/enc_conv_2/Conv2D/ReadVariableOp:0
[08/21/2023-14:52:01] [V] [TRT] StatefulPartitionedCall/model/enc_conv_2/Conv2D [Conv] inputs: [StatefulPartitionedCall/model/re_lu/Relu:0 -> (-1, 32, 128, 128)[FLOAT]], [StatefulPartitionedCall/model/enc_conv_2/Conv2D/ReadVariableOp:0 -> (64, 32, 3, 3)[FLOAT]], 
[08/21/2023-14:52:01] [V] [TRT] Convolution input dimensions: (-1, 32, 128, 128)
[08/21/2023-14:52:01] [V] [TRT] Registering layer: StatefulPartitionedCall/model/enc_conv_2/Conv2D for ONNX node: StatefulPartitionedCall/model/enc_conv_2/Conv2D
[08/21/2023-14:52:01] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[08/21/2023-14:52:01] [V] [TRT] Convolution output dimensions: (-1, 64, 128, 128)
[08/21/2023-14:52:01] [V] [TRT] Registering tensor: StatefulPartitionedCall/model/enc_conv_2/Conv2D:0 for ONNX tensor: StatefulPartitionedCall/model/enc_conv_2/Conv2D:0
[08/21/2023-14:52:01] [V] [TRT] StatefulPartitionedCall/model/enc_conv_2/Conv2D [Conv] outputs: [StatefulPartitionedCall/model/enc_conv_2/Conv2D:0 -> (-1, 64, 128, 128)[FLOAT]], 
[08/21/2023-14:52:01] [V] [TRT] Parsing node: StatefulPartitionedCall/model/re_lu_1/Relu [Relu]
[08/21/2023-14:52:01] [V] [TRT] Searching for input: StatefulPartitionedCall/model/enc_conv_2/Conv2D:0
[08/21/2023-14:52:01] [V] [TRT] StatefulPartitionedCall/model/re_lu_1/Relu [Relu] inputs: [StatefulPartitionedCall/model/enc_conv_2/Conv2D:0 -> (-1, 64, 128, 128)[FLOAT]], 
[08/21/2023-14:52:01] [V] [TRT] Registering layer: StatefulPartitionedCall/model/re_lu_1/Relu for ONNX node: StatefulPartitionedCall/model/re_lu_1/Relu
[08/21/2023-14:52:01] [V] [TRT] Registering tensor: Identity:0_0 for ONNX tensor: Identity:0
[08/21/2023-14:52:01] [V] [TRT] StatefulPartitionedCall/model/re_lu_1/Relu [Relu] outputs: [Identity:0 -> (-1, 64, 128, 128)[FLOAT]], 
[08/21/2023-14:52:01] [V] [TRT] Marking Identity:0_0 as output: Identity:0
[08/21/2023-14:52:01] [I] Finished parsing network model. Parse time: 0.00165207
[08/21/2023-14:52:01] [V] Trying to set exclusive file lock ./timing.cache.lock
[08/21/2023-14:52:01] [V] File locked in 2.679e-06 seconds.
[08/21/2023-14:52:01] [I] Loaded 39725 bytes of timing cache from ./timing.cache
[08/21/2023-14:52:01] [V] Trying to remove exclusive file lock ./timing.cache.lock
[08/21/2023-14:52:01] [V] File unlocked in 4.478e-06 seconds.
[08/21/2023-14:52:01] [V] [TRT] Loaded 380 timing cache entries.
[08/21/2023-14:52:01] [V] [TRT] Loaded 59 bytes of code generator cache.
[08/21/2023-14:52:01] [V] [TRT] Original: 4 layers
[08/21/2023-14:52:01] [V] [TRT] After dead-layer removal: 4 layers
[08/21/2023-14:52:01] [V] [TRT] Graph construction completed in 0.000334393 seconds.
[08/21/2023-14:52:01] [V] [TRT] After Myelin optimization: 4 layers
[08/21/2023-14:52:01] [V] [TRT] Applying ScaleNodes fusions.
[08/21/2023-14:52:01] [V] [TRT] After scale fusion: 4 layers
[08/21/2023-14:52:01] [V] [TRT] Running: ConvReluFusion on StatefulPartitionedCall/model/enc_conv_1/Conv2D
[08/21/2023-14:52:01] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model/enc_conv_1/Conv2D with StatefulPartitionedCall/model/re_lu/Relu
[08/21/2023-14:52:01] [V] [TRT] Running: ConvReluFusion on StatefulPartitionedCall/model/enc_conv_2/Conv2D
[08/21/2023-14:52:01] [V] [TRT] ConvReluFusion: Fusing StatefulPartitionedCall/model/enc_conv_2/Conv2D with StatefulPartitionedCall/model/re_lu_1/Relu
[08/21/2023-14:52:01] [V] [TRT] After dupe layer removal: 2 layers
[08/21/2023-14:52:01] [V] [TRT] After final dead-layer removal: 2 layers
[08/21/2023-14:52:01] [V] [TRT] After tensor merging: 2 layers
[08/21/2023-14:52:01] [V] [TRT] After vertical fusions: 2 layers
[08/21/2023-14:52:01] [V] [TRT] After dupe layer removal: 2 layers
[08/21/2023-14:52:01] [V] [TRT] After final dead-layer removal: 2 layers
[08/21/2023-14:52:01] [V] [TRT] After tensor merging: 2 layers
[08/21/2023-14:52:01] [V] [TRT] After slice removal: 2 layers
[08/21/2023-14:52:01] [V] [TRT] After concat removal: 2 layers
[08/21/2023-14:52:01] [V] [TRT] Trying to split Reshape and strided tensor
[08/21/2023-14:52:01] [I] [TRT] Graph optimization time: 0.000226999 seconds.
[08/21/2023-14:52:01] [V] [TRT] Building graph using backend strategy 2
[08/21/2023-14:52:01] [I] [TRT] Global timing cache in use. Profiling results in this builder pass will be stored.
[08/21/2023-14:52:01] [V] [TRT] Constructing optimization profile number 0 [1/1].
[08/21/2023-14:52:01] [V] [TRT] Applying generic optimizations to the graph for inference.
[08/21/2023-14:52:01] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[08/21/2023-14:52:01] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Float(49152,16384,128,1) -> Float(524288,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Float(49152,1,384,3) -> Float(524288,1,4096,32) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Float(16384,1:4,128,1) -> Float(524288,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Float(16384,1:4,128,1) -> Float(131072,1:4,1024,8) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(49152,16384,128,1) -> Half(524288,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (CaskConvolution[0x80000009])
[08/21/2023-14:52:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (CaskFlattenConvolution[0x80000036])
[08/21/2023-14:52:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (CudnnConvolution[0x80000000])
[08/21/2023-14:52:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(32768,1:2,256,2) -> Half(262144,1:2,2048,16) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(16384,1:4,128,1) -> Half(131072,1:4,1024,8) ***************
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (CaskConvolution[0x80000009])
[08/21/2023-14:52:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (CaskFlattenConvolution[0x80000036])
[08/21/2023-14:52:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(16384,1:4,128,1) -> Half(65536,1:8,512,4) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(16384,1:8,128,1) -> Float(524288,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (CaskConvolution[0x80000009])
[08/21/2023-14:52:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (CaskFlattenConvolution[0x80000036])
[08/21/2023-14:52:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(16384,1:8,128,1) -> Half(65536,1:8,512,4) ***************
[08/21/2023-14:52:01] [V] [TRT] =============== Computing costs for StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Float(524288,16384,128,1) -> Float(1048576,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Float(524288,1,4096,32) -> Float(1048576,1,8192,64) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Float(131072,1:4,1024,8) -> Float(1048576,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Float(131072,1:4,1024,8) -> Float(262144,1:4,2048,16) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(524288,16384,128,1) -> Half(1048576,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (CaskConvolution[0x80000009])
[08/21/2023-14:52:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (CaskFlattenConvolution[0x80000036])
[08/21/2023-14:52:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (CudnnConvolution[0x80000000])
[08/21/2023-14:52:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(262144,1:2,2048,16) -> Half(524288,1:2,4096,32) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(131072,1:4,1024,8) -> Half(262144,1:4,2048,16) ***************
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (CaskConvolution[0x80000009])
[08/21/2023-14:52:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (CaskFlattenConvolution[0x80000036])
[08/21/2023-14:52:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(65536,1:8,512,4) -> Float(1048576,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (CaskConvolution[0x80000009])
[08/21/2023-14:52:01] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] --------------- Timing Runner: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (CaskFlattenConvolution[0x80000036])
[08/21/2023-14:52:01] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning format combination: Half(65536,1:8,512,4) -> Half(131072,1:8,1024,8) ***************
[08/21/2023-14:52:01] [V] [TRT] =============== Computing reformatting costs
[08/21/2023-14:52:01] [V] [TRT] =============== Computing reformatting costs: 
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384,128,1) -> Float(49152,1,384,3) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384,128,1) -> Float(16384,1:4,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384,128,1) -> Half(32768,1:2,256,2) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384,128,1) -> Half(16384,1:4,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(49152,16384,128,1) -> Half(16384,1:8,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] =============== Computing reformatting costs
[08/21/2023-14:52:01] [V] [TRT] =============== Computing reformatting costs: 
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,16384,128,1) -> Float(524288,1,4096,32) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,16384,128,1) -> Float(131072,1:4,1024,8) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,16384,128,1) -> Half(262144,1:2,2048,16) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,16384,128,1) -> Half(65536,1:8,512,4) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,1,4096,32) -> Float(524288,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,1,4096,32) -> Float(131072,1:4,1024,8) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,1,4096,32) -> Half(262144,1:2,2048,16) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(524288,1,4096,32) -> Half(65536,1:8,512,4) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(131072,1:4,1024,8) -> Float(524288,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(131072,1:4,1024,8) -> Float(524288,1,4096,32) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(131072,1:4,1024,8) -> Half(262144,1:2,2048,16) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(131072,1:4,1024,8) -> Half(65536,1:8,512,4) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(262144,1:2,2048,16) -> Float(524288,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(262144,1:2,2048,16) -> Float(524288,1,4096,32) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(262144,1:2,2048,16) -> Float(131072,1:4,1024,8) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(262144,1:2,2048,16) -> Half(65536,1:8,512,4) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(65536,1:8,512,4) -> Float(524288,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(65536,1:8,512,4) -> Float(524288,1,4096,32) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(65536,1:8,512,4) -> Float(131072,1:4,1024,8) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(65536,1:8,512,4) -> Half(262144,1:2,2048,16) ***************
[08/21/2023-14:52:01] [V] [TRT] =============== Computing reformatting costs
[08/21/2023-14:52:01] [V] [TRT] =============== Computing reformatting costs: 
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(1048576,1,8192,64) -> Float(1048576,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Float(262144,1:4,2048,16) -> Float(1048576,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(524288,1:2,4096,32) -> Float(1048576,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] *************** Autotuning Reformat: Half(131072,1:8,1024,8) -> Float(1048576,16384,128,1) ***************
[08/21/2023-14:52:01] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (input_1:0) from Float(49152,16384,128,1) to Half(16384,1:4,128,1)
[08/21/2023-14:52:01] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (Identity:0) from Half(131072,1:8,1024,8) to Float(1048576,16384,128,1)
[08/21/2023-14:52:01] [V] [TRT] Formats and tactics selection completed in 0.0208397 seconds.
[08/21/2023-14:52:01] [V] [TRT] After reformat layers: 4 layers
[08/21/2023-14:52:01] [V] [TRT] Total number of blocks in pre-optimized block assignment: 4
[08/21/2023-14:52:01] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[08/21/2023-14:52:01] [V] [TRT] Layer: StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu Host Persistent: 5296 Device Persistent: 0 Scratch Memory: 0
[08/21/2023-14:52:01] [V] [TRT] Layer: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu Host Persistent: 5296 Device Persistent: 0 Scratch Memory: 0
[08/21/2023-14:52:01] [V] [TRT] Skipped printing memory information for 2 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
[08/21/2023-14:52:01] [I] [TRT] Total Host Persistent Memory: 10592
[08/21/2023-14:52:01] [I] [TRT] Total Device Persistent Memory: 0
[08/21/2023-14:52:01] [I] [TRT] Total Scratch Memory: 0
[08/21/2023-14:52:01] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 4 MiB
[08/21/2023-14:52:01] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 3 steps to complete.
[08/21/2023-14:52:01] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.010231ms to assign 2 blocks to 3 nodes requiring 100663296 bytes.
[08/21/2023-14:52:01] [V] [TRT] Total number of blocks in optimized block assignment: 2
[08/21/2023-14:52:01] [I] [TRT] Total Activation Memory: 100663296
[08/21/2023-14:52:01] [V] [TRT] Finalize: StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu Set kernel index: 0
[08/21/2023-14:52:01] [V] [TRT] Finalize: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu Set kernel index: 1
[08/21/2023-14:52:01] [V] [TRT] Total number of generated kernels selected for the engine: 2
[08/21/2023-14:52:01] [V] [TRT] Kernel: 0 CASK_STATIC
[08/21/2023-14:52:01] [V] [TRT] Kernel: 1 CASK_STATIC
[08/21/2023-14:52:01] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS
[08/21/2023-14:52:01] [V] [TRT] Engine generation completed in 0.0242675 seconds.
[08/21/2023-14:52:01] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[08/21/2023-14:52:01] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[08/21/2023-14:52:01] [W] [TRT] Check verbose logs for the list of affected weights.
[08/21/2023-14:52:01] [W] [TRT] - 1 weights are affected by this issue: Detected subnormal FP16 values.
[08/21/2023-14:52:01] [V] [TRT]   List of affected weights: StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu.weight
[08/21/2023-14:52:01] [V] [TRT] Engine Layer Information:
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu, Tactic: 0x00000000000003ea, input_1:0 (Float[32,3,128,128]) -> Reformatted Input Tensor 0 to StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (Half[32,3:4,128,128])
Layer(CaskConvolution): StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu, Tactic: 0xa47a4e5ec2ac6617, Reformatted Input Tensor 0 to StatefulPartitionedCall/model/enc_conv_1/Conv2D + StatefulPartitionedCall/model/re_lu/Relu (Half[32,3:4,128,128]) -> StatefulPartitionedCall/model/re_lu/Relu:0 (Half[32,32:8,128,128])
Layer(CaskConvolution): StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu, Tactic: 0x1bf48a356bd0c083, StatefulPartitionedCall/model/re_lu/Relu:0 (Half[32,32:8,128,128]) -> Reformatted Output Tensor 0 to StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (Half[32,64:8,128,128])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu, Tactic: 0x00000000000003ea, Reformatted Output Tensor 0 to StatefulPartitionedCall/model/enc_conv_2/Conv2D + StatefulPartitionedCall/model/re_lu_1/Relu (Half[32,64:8,128,128]) -> Identity:0 (Float[32,64,128,128])
[08/21/2023-14:52:01] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)
[08/21/2023-14:52:01] [V] [TRT] Adding 1 engine(s) to plan file.
[08/21/2023-14:52:01] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2054, GPU 1316 (MiB)
[08/21/2023-14:52:01] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[08/21/2023-14:52:01] [V] Trying to set exclusive file lock ./timing.cache.lock
[08/21/2023-14:52:01] [V] File locked in 2.912e-06 seconds.
[08/21/2023-14:52:01] [I] Loaded 39725 bytes of timing cache from ./timing.cache
[08/21/2023-14:52:01] [V] [TRT] Loaded 380 timing cache entries.
[08/21/2023-14:52:01] [V] [TRT] Loaded 59 bytes of code generator cache.
[08/21/2023-14:52:01] [V] [TRT] Serializing timing cache. UUID = GPU-8aa1cfe7-2ce9-1279-c30c-a906cf668caa, commit ID = 558ddbb60946c7d0
[08/21/2023-14:52:01] [V] [TRT] Serialized 59 bytes of code generator cache.
[08/21/2023-14:52:01] [V] [TRT] Serialized 59 bytes of code generator cache.
[08/21/2023-14:52:01] [V] [TRT] Serialized 380 timing cache entries
[08/21/2023-14:52:01] [I] Saved 39725 bytes of timing cache to ./timing.cache
[08/21/2023-14:52:01] [V] Trying to remove exclusive file lock ./timing.cache.lock
[08/21/2023-14:52:01] [V] File unlocked in 5.434e-06 seconds.
[08/21/2023-14:52:01] [V] [TRT] Deleting timing cache: 380 entries, served 0 hits since creation.
[08/21/2023-14:52:01] [V] [TRT] Deleting timing cache: 380 entries, served 42 hits since creation.
[08/21/2023-14:52:01] [I] Engine built in 5.90043 sec.
[08/21/2023-14:52:01] [I] [TRT] Loaded engine size: 0 MiB
[08/21/2023-14:52:01] [V] [TRT] Deserialization required 777 microseconds.
[08/21/2023-14:52:01] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[08/21/2023-14:52:01] [I] Engine deserialized in 0.000930434 sec.
[08/21/2023-14:52:01] [I] Skipped inference phase since --skipInference is added.
&&&& PASSED TensorRT.trtexec [TensorRT v8601] # trtexec --verbose --nvtxMode=verbose --buildOnly --workspace=8192 --onnx=one_layer_model_gen/onnx_dummies/dummy_no_quant_NCHW.onnx --saveEngine=one_layer_model_gen/engine_data_no_quant_NCHW_fp32_chw/dummy_no_quant_NCHW.onnx.engine --timingCacheFile=./timing.cache --fp16 --inputIOFormats=fp32:chw --outputIOFormats=fp32:chw --shapes=input_1:0:32x3x128x128
